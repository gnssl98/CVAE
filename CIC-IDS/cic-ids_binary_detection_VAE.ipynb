{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db7ba57a",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"cic_ids_smote03.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee5138ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"D:/dataset/cleaned_improved_cicids2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c8ddb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BENIGN                        1594540\n",
       "Portscan                       159066\n",
       "DoS Hulk                       158468\n",
       "DDoS                            95144\n",
       "Infiltration - Portscan         71767\n",
       "DoS GoldenEye                    7567\n",
       "FTP-Patator                      3972\n",
       "DoS Slowloris                    3859\n",
       "SSH-Patator                      2961\n",
       "DoS Slowhttptest                 1740\n",
       "Botnet                            736\n",
       "Web Attack - Brute Force           73\n",
       "Infiltration                       36\n",
       "Web Attack - XSS                   18\n",
       "Web Attack - SQL Injection         13\n",
       "Heartbleed                         11\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29e1fc8",
   "metadata": {},
   "source": [
    "BENIGN                        1594540<br>\n",
    "Portscan                       159066<br>\n",
    "DoS Hulk                       158468<br>\n",
    "DDoS                            95144<br>\n",
    "Infiltration - Portscan         71767<br>\n",
    "DoS GoldenEye                    7567<br>\n",
    "FTP-Patator                      3972<br>\n",
    "DoS Slowloris                    3859<br>\n",
    "SSH-Patator                      2961<br>\n",
    "DoS Slowhttptest                 1740<br>\n",
    "Botnet                            736<br>\n",
    "Web Attack - Brute Force           73<br>\n",
    "Infiltration                       36<br>\n",
    "Web Attack - XSS                   18<br>\n",
    "Web Attack - SQL Injection         13<br>\n",
    "Heartbleed                         11<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c0c8dd1-d7ab-4aa7-ad0a-b9dab95dc28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Protocol  Flow Duration  Total Fwd Packet  Total Bwd packets  \\\n",
      "0         0      119719148               231                  0   \n",
      "1        17       65511209                 6                  6   \n",
      "2        17      113976922               267                  0   \n",
      "3        17       67037196                 8                  8   \n",
      "4        17       68045057                 8                  8   \n",
      "\n",
      "   Total Length of Fwd Packet  Total Length of Bwd Packet  \\\n",
      "0                           0                           0   \n",
      "1                         288                         288   \n",
      "2                       20447                           0   \n",
      "3                         384                         384   \n",
      "4                         384                         384   \n",
      "\n",
      "   Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
      "0                      0                      0                0.000000   \n",
      "1                     48                     48               48.000000   \n",
      "2                    153                     37               76.580524   \n",
      "3                     48                     48               48.000000   \n",
      "4                     48                     48               48.000000   \n",
      "\n",
      "   Fwd Packet Length Std  ...  Active Max  Active Min   Idle Mean  \\\n",
      "0               0.000000  ...    22509459          17  12685486.0   \n",
      "1               0.000000  ...     1506210     1506210  64004884.0   \n",
      "2              44.140625  ...    10983883          14  25498178.0   \n",
      "3               0.000000  ...    11034681    11034681  55956316.0   \n",
      "4               0.000000  ...    11043596    11043596  56943904.0   \n",
      "\n",
      "       Idle Std  Idle Max  Idle Min  ICMP Code  ICMP Type  \\\n",
      "0  5.296658e+06  20694308   6499982          0          0   \n",
      "1  0.000000e+00  64004884  64004884          0          0   \n",
      "2  1.883305e+07  48523116   5463561          0          0   \n",
      "3  0.000000e+00  55956316  55956316          0          0   \n",
      "4  0.000000e+00  56943904  56943904          0          0   \n",
      "\n",
      "   Total TCP Flow Time  Label  \n",
      "0                    0      0  \n",
      "1                    0      0  \n",
      "2                    0      0  \n",
      "3                    0      0  \n",
      "4                    0      0  \n",
      "\n",
      "[5 rows x 83 columns]\n"
     ]
    }
   ],
   "source": [
    "# 이진분류\n",
    "df['Label'] = df['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
    "\n",
    "# 변경된 데이터프레임 확인\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c19b4d94-bb98-4e0c-aad8-994594a85d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "tmp = df.drop(labels = 'Label',axis=1)\n",
    "labels = df['Label']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(tmp)\n",
    "\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=tmp.columns)  # 스케일된 데이터를 DataFrame으로 변환\n",
    "df_merged = pd.concat([X_scaled_df, labels.reset_index(drop=True)], axis=1)  # Index 정렬 후 병합\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b75365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1889973, 83), (209998, 83))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(df_merged, test_size=0.1, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9872e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159227, 83)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal = X_train[X_train['Label'] == 0]\n",
    "X_train_normal.shape\n",
    "\n",
    "X_test_normal = X_test[X_test['Label'] == 0]\n",
    "X_test_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7624c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_not_normal = X_train[X_train['Label'] !=0]\n",
    "\n",
    "X_test = pd.concat([X_test, X_train_not_normal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14f36da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = X_test['Label']\n",
    "X_test = X_test.drop(labels='Label',axis=1)\n",
    "y_train_normal = X_train_normal['Label']\n",
    "X_train_normal = X_train_normal.drop(labels='Label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56bcdedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dropout, Dense, LSTM, TimeDistributed, RepeatVector, Conv1D, Conv1DTranspose\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras_self_attention import SeqWeightedAttention, SeqSelfAttention\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b2a5899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " InputFeatures (InputLayer)     [(None, 82)]         0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          10624       ['InputFeatures[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 20)           1300        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 10)           210         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 10)           210         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 10)           0           ['dense_3[0][0]',                \n",
      "                                                                  'dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 20)           220         ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           1344        ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 128)          8320        ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 82)           10578       ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 10)          0           ['dense_4[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.square_1 (TFOpLambda)  (None, 10)           0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 10)          0           ['tf.__operators__.add[0][0]',   \n",
      " )                                                                'tf.math.square_1[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.exp (TFOpLambda)       (None, 10)           0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLambda  (None, 10)          0           ['tf.math.subtract_1[0][0]',     \n",
      " )                                                                'tf.math.exp[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 82)           0           ['InputFeatures[0][0]',          \n",
      "                                                                  'dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  (None,)             0           ['tf.math.subtract_2[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.square (TFOpLambda)    (None, 82)           0           ['tf.math.subtract[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None,)              0           ['tf.math.reduce_sum_1[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None,)             0           ['tf.math.square[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None,)             0           ['tf.math.multiply[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None,)             0           ['tf.math.reduce_sum[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  ()                  0           ['tf.__operators__.add_1[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " add_loss (AddLoss)             ()                   0           ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 41,062\n",
      "Trainable params: 41,062\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "40369/40369 [==============================] - 107s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "40369/40369 [==============================] - 104s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "23485/40369 [================>.............] - ETA: 43s - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_normal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_normal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhistory\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myvenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myvenv\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myvenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myvenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myvenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myvenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myvenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myvenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myvenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, Model, Input\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "latent_dim = 10  # Latent 공간 차원\n",
    "inter_dim = 20   # 중간 층 차원\n",
    "\n",
    "# Sampling function for reparameterization trick\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    batch_size = tf.shape(z_mean)[0]\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1.)\n",
    "    return z_mean + z_log_sigma * epsilon\n",
    "\n",
    "# VAE 손실 함수 정의\n",
    "def vae_loss(x, x_decoded_mean, z_mean, z_log_sigma):\n",
    "    reconstruction_loss = K.sum(K.square(x - x_decoded_mean), axis=1)  # MSE 기반 복원 손실\n",
    "    kl_loss = -0.5 * K.sum(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)  # KL 다이버전스\n",
    "    kl_loss_weighted = kl_loss * 0.0001  # KL 손실 가중치 적용\n",
    "    total_loss = K.mean(reconstruction_loss + kl_loss_weighted)\n",
    "    return total_loss\n",
    "\n",
    "# VAE 모델 생성\n",
    "def vae(X_train):\n",
    "    features = X_train.shape[1]  # 입력 차원\n",
    "    input_x = Input(shape=(features,), name='InputFeatures')  # 2D 입력 (샘플, 특징)\n",
    "\n",
    "    # Encoder\n",
    "    h = layers.Dense(128, activation='relu')(input_x)\n",
    "    h = layers.Dense(64, activation='relu')(h)\n",
    "    h = layers.Dense(inter_dim, activation='relu')(h)\n",
    "\n",
    "    # Latent space\n",
    "    z_mean = layers.Dense(latent_dim)(h)\n",
    "    z_log_sigma = layers.Dense(latent_dim)(h)\n",
    "    z = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "    # Decoder\n",
    "    decoder = layers.Dense(inter_dim, activation='relu')(z)\n",
    "    decoder = layers.Dense(64, activation='relu')(decoder)\n",
    "    decoder = layers.Dense(128, activation='relu')(decoder)\n",
    "    decoder = layers.Dense(features, activation='linear')(decoder)  # 원래 feature 차원으로 복원\n",
    "\n",
    "    model = Model(input_x, decoder)\n",
    "    model.add_loss(vae_loss(input_x, decoder, z_mean, z_log_sigma))  # VAE Loss 추가\n",
    "\n",
    "    return model\n",
    "\n",
    "# VAE 모델 생성\n",
    "model = vae(X_train_normal)\n",
    "model.summary()\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005))\n",
    "\n",
    "# EarlyStopping 콜백\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train_normal, X_train_normal,\n",
    "                    shuffle=True,\n",
    "                    epochs=100,\n",
    "                    validation_split=0.1,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stopping]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ac23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the training losses\n",
    "fig, ax = plt.subplots(figsize=(14, 6), dpi=80)\n",
    "ax.plot(history['loss'], 'b', label='Train', linewidth=2)\n",
    "ax.plot(history['val_loss'], 'r', label='Validation', linewidth=2)\n",
    "ax.set_title('Model loss', fontsize=16)\n",
    "ax.set_ylabel('Loss (mae)')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aea97b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(X):\n",
    "    flattened_X = np.empty((X.shape[0], X.shape[2]))  # sample x features array.\n",
    "    for i in range(X.shape[0]):\n",
    "        flattened_X[i] = X[i, (X.shape[1]-1), :]\n",
    "    return(flattened_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ad3446",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x_predictions = model.predict([X_test, y_test])\n",
    "#mse = np.mean(np.power(flatten(test_X_selected) - flatten(valid_x_predictions), 2), axis=1)\n",
    "\n",
    "mse = np.mean(np.power(X_test - valid_x_predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': y_test.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713fde56",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b078f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터프레임 준비\n",
    "true_class = error_df['true_class'].astype(str)\n",
    "reconstruction_error = error_df['reconstruction_error']\n",
    "\n",
    "# 박스 플롯 그리기\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.boxplot(\n",
    "    [reconstruction_error[true_class == cls] for cls in sorted(true_class.unique())],\n",
    "    labels=sorted(true_class.unique()),\n",
    "    showfliers=False,\n",
    "    vert=True,\n",
    "    patch_artist=True\n",
    ")\n",
    "\n",
    "plt.ylabel('Distribution')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dafb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define the range of threshold values\n",
    "threshold_range = np.arange(0, 5.1, 0.01)\n",
    "\n",
    "# List to store F1 scores for each threshold\n",
    "f1_scores = []\n",
    "\n",
    "# Loop through each threshold and calculate F1 score\n",
    "for threshold in threshold_range:\n",
    "    y_pred = [0 if e < threshold else 1 for e in error_df.reconstruction_error.values]\n",
    "    f1 = f1_score(error_df.true_class, y_pred)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Find the threshold with the highest F1 score\n",
    "best_threshold = threshold_range[np.argmax(f1_scores)]\n",
    "best_f1_score = max(f1_scores)\n",
    "\n",
    "print(f\"Best threshold: {best_threshold}\")\n",
    "print(f\"Best F1 score: {best_f1_score}\")\n",
    "\n",
    "# Optionally, you can plot the F1 scores across the threshold range\n",
    "plt.plot(threshold_range, f1_scores, marker='o')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs Threshold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a849e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming you have already defined LABELS, threshold, and y_pred\n",
    "\n",
    "LABELS = [\"Attack\", \"Normal\"]\n",
    "\n",
    "y_pred = [0 if e < threshold else 1 for e in error_df.reconstruction_error.values]\n",
    "conf_matrix = confusion_matrix(error_df.true_class, y_pred)\n",
    "\n",
    "# Create the figure and axis\n",
    "plt.figure(figsize=(12, 12))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the confusion matrix using imshow\n",
    "cax = ax.matshow(conf_matrix, cmap=plt.cm.Blues)\n",
    "\n",
    "# Add color bar\n",
    "plt.colorbar(cax)\n",
    "\n",
    "# Set the labels for the axes\n",
    "ax.set_xticks(np.arange(len(LABELS)))\n",
    "ax.set_yticks(np.arange(len(LABELS)))\n",
    "\n",
    "ax.set_xticklabels(LABELS)\n",
    "ax.set_yticklabels(LABELS)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Predicted class')\n",
    "plt.ylabel('True class')\n",
    "plt.title('Confusion matrix')\n",
    "\n",
    "# Annotate the confusion matrix with the counts\n",
    "for i in range(len(LABELS)):\n",
    "    for j in range(len(LABELS)):\n",
    "        ax.text(j, i, format(conf_matrix[i, j], 'd'),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if conf_matrix[i, j] > conf_matrix.max() / 2 else \"black\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c84077e-5687-45a3-a792-0c6a183e4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Assuming y_test and reconstruction_error have been defined\n",
    "fpr, tpr, thresholds = roc_curve(y_test, reconstruction_error)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6faea4-56e3-4d31-9173-56937636ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "precision, recall, f1,_ = precision_recall_fscore_support(y_test,y_pred,average='binary')\n",
    "print ('Accuracy Score :',accuracy_score(error_df.true_class, y_pred) )\n",
    "print ('Precision :',precision )\n",
    "print ('Recall :',recall )\n",
    "print ('F1 :',f1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc59e5d2-2021-4465-9cff-c1704c952a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ROC Score : {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6311bc42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
